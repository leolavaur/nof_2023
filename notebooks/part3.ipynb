{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: How to Secure Federated Learning in Network Monitoring\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phdcybersec/nof_2023/blob/main/notebooks/part3.ipynb)\n",
    "\n",
    "In this final part, we will see the security of a federated intrusion detection system. We will use the same dataset as in Part II, but we will now assume that an attacker is now sending malicious updates to negatively impact the system. We will see how the system can be made more robust to such attacks using a modified aggregation algorithm called FoolsGold.\n",
    "\n",
    "## Section 0: Prerequisites\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "First, let's make sure that the correct dependencies are installed. If you are running this notebook locally, please see the README for instructions on how to install the appropriate dependencies. If you are running this notebook on Google Colab, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we are running on Google Colab\n",
    "import os\n",
    "from IPython.core.getipython import get_ipython\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !git clone https://github.com/phdcybersec/nof_2023.git\n",
    "    %pip install poetry\n",
    "    %pip install -r <(poetry export -C nof_2023/)\n",
    "    !rm -r nof_2023/\n",
    "else:\n",
    "    # if not, we assume we are running on a local machine were dependencies are already\n",
    "    # installed; cd to a temporary directory to avoid cluttering the current directory\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(\"/tmp/nslkdd\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    os.chdir(\"/tmp/nslkdd\")\n",
    "\n",
    "# download the dataset\n",
    "if not os.path.exists(\"nslkdd/KDDTrain+.txt\"):\n",
    "    !curl -Lo nslkdd.zip http://205.174.165.80/CICDataset/NSL-KDD/Dataset/NSL-KDD.zip\n",
    "    !unzip -o -d nslkdd nslkdd.zip && rm nslkdd.zip\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all dependencies installed, we can import everything we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import functools\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "from typing import cast, Callable\n",
    "\n",
    "import flwr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from flwr.common import Metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth\n",
    "from tensorflow import keras\n",
    "from flwr.server.history import History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and check that everything is working as expected. If you have access to a GPU, either on Colab on on your local machine, it should be detected and used by TensorFlow. We also use a Flower utility function to allow TensorFlow to share the GPU memory between multiple processes, which is necessary for running multiple clients in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(f\"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "enable_tf_gpu_growth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow others to reproduce your results with certitude, set a seed for all the pseudo-random number generators (PRNG) that you use. You should also run your threads deterministically, in case your ML backend optimize training. This will have a negative impact on the performance. On TensorFlow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1138\n",
    "keras.utils.set_random_seed(SEED)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Dataset and model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is the same as in Part II. We will use the same dataset, and we will split it into a training set and a test set. We will also split the training set into multiple clients, and we will use the same partitioning as in Part II. We will also reuse our model from Part II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 1\n",
    "NUM_CLIENTS = 10\n",
    "NUM_ROUNDS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nslkdd() -> (\n",
    "    tuple[\n",
    "        tuple[pd.DataFrame, pd.DataFrame, pd.Series],\n",
    "        tuple[pd.DataFrame, pd.DataFrame, pd.Series],\n",
    "    ]\n",
    "):\n",
    "    # column names:\n",
    "    # https://github.com/kahramankostas/NSL-KDD-binary-classification-with-Transformer#reading-csv-files\n",
    "    c_names = [\n",
    "        \"duration\",\n",
    "        \"protocol_type\",\n",
    "        \"service\",\n",
    "        \"flag\",\n",
    "        \"src_bytes\",\n",
    "        \"dst_bytes\",\n",
    "        \"land\",\n",
    "        \"wrong_fragment\",\n",
    "        \"urgent\",\n",
    "        \"hot\",\n",
    "        \"num_failed_logins\",\n",
    "        \"logged_in\",\n",
    "        \"num_compromised\",\n",
    "        \"root_shell\",\n",
    "        \"su_attempted\",\n",
    "        \"num_root\",\n",
    "        \"num_file_creations\",\n",
    "        \"num_shells\",\n",
    "        \"num_access_files\",\n",
    "        \"num_outbound_cmds\",\n",
    "        \"is_host_login\",\n",
    "        \"is_guest_login\",\n",
    "        \"count\",\n",
    "        \"srv_count\",\n",
    "        \"serror_rate\",\n",
    "        \"srv_serror_rate\",\n",
    "        \"rerror_rate\",\n",
    "        \"srv_rerror_rate\",\n",
    "        \"same_srv_rate\",\n",
    "        \"diff_srv_rate\",\n",
    "        \"srv_diff_host_rate\",\n",
    "        \"dst_host_count\",\n",
    "        \"dst_host_srv_count\",\n",
    "        \"dst_host_same_srv_rate\",\n",
    "        \"dst_host_diff_srv_rate\",\n",
    "        \"dst_host_same_src_port_rate\",\n",
    "        \"dst_host_srv_diff_host_rate\",\n",
    "        \"dst_host_serror_rate\",\n",
    "        \"dst_host_srv_serror_rate\",\n",
    "        \"dst_host_rerror_rate\",\n",
    "        \"dst_host_srv_rerror_rate\",\n",
    "        \"label\",\n",
    "        \"difficulty\",\n",
    "    ]\n",
    "\n",
    "    # load datasets\n",
    "    train_df = pd.read_csv(\"./nslkdd/KDDTrain+.txt\", names=c_names)\n",
    "    test_df = pd.read_csv(\"./nslkdd/KDDTest+.txt\", names=c_names)\n",
    "\n",
    "    # extract the labels for the outputs (will serve as metadata)\n",
    "    m_train = train_df[\"label\"]\n",
    "    m_test = test_df[\"label\"]\n",
    "\n",
    "    # drop labels for input, and difficulty\n",
    "    train_df = train_df.drop(columns=[\"label\", \"difficulty\"])\n",
    "    test_df = test_df.drop(columns=[\"label\", \"difficulty\"])\n",
    "\n",
    "    # convert classes to numerical values\n",
    "    X_train = pd.get_dummies(train_df)\n",
    "    X_test = pd.get_dummies(test_df)\n",
    "\n",
    "    # reindex the testing dataset so its columns match the training columns\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    # normalize input dataframes\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train[X_train.columns] = scaler.transform(X_train)\n",
    "    X_test[X_test.columns] = scaler.transform(X_test)\n",
    "\n",
    "    # transform outputs to binary classification\n",
    "    y_train = m_train.apply(lambda x: False if x == \"normal\" else True)\n",
    "    y_test = m_test.apply(lambda x: False if x == \"normal\" else True)\n",
    "\n",
    "    # apply one-hot encoding to outputs\n",
    "    y_train = pd.get_dummies(y_train, prefix=\"Malicious\")\n",
    "    y_test = pd.get_dummies(y_test, prefix=\"Malicious\")\n",
    "\n",
    "    return (X_train, y_train, m_train), (X_test, y_test, m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train, m_train), (X_test, y_test, m_test) = load_nslkdd()\n",
    "ATTACK_LABELS = m_train.unique()[m_train.unique() != \"normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "print(n_features)\n",
    "\n",
    "\n",
    "def mk_model() -> keras.Model:\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(n_features,)),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"],\n",
    "        # run_eagerly=True,  # test due to the bug in ray\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "mk_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep attacks that are well detected\n",
    "# (d[\"rate\"] > 0.5) & (d[\"count\"] > 100)\n",
    "DROPABLE_CLASSES = [\n",
    "    \"neptune\",\n",
    "    \"normal\",\n",
    "    \"saint\",\n",
    "    \"mscan\",\n",
    "    \"smurf\",\n",
    "    \"satan\",\n",
    "    \"ipsweep\",\n",
    "    \"portsweep\",\n",
    "]\n",
    "\n",
    "\n",
    "def partition(\n",
    "    num_shards: int,\n",
    "    dataset: tuple[pd.DataFrame, pd.DataFrame, pd.Series],\n",
    "    n_drop: int = 0,\n",
    ") -> list[tuple[pd.DataFrame, pd.DataFrame, pd.Series]]:\n",
    "    \"\"\"Partition the NSL-KDD dataset.\"\"\"\n",
    "    X, y, m = dataset\n",
    "    partitions = []\n",
    "    # We keep all partitions equal-sized in this example\n",
    "    partition_size = math.floor(len(X) / num_shards)\n",
    "    shuffle_idx = np.random.permutation(len(X))\n",
    "    X, y, m = X.iloc[shuffle_idx], y.iloc[shuffle_idx], m.iloc[shuffle_idx]\n",
    "\n",
    "    for i in range(num_shards):\n",
    "        idx_from, idx_to = i * partition_size, (i + 1) * partition_size\n",
    "\n",
    "        X_part = X[idx_from:idx_to]\n",
    "        y_part = y[idx_from:idx_to]\n",
    "        m_part = m[idx_from:idx_to]\n",
    "\n",
    "        # randomly remove NUM_REMOVED_CLASSES from each partition\n",
    "        _rm_classes = np.random.choice(DROPABLE_CLASSES, n_drop, replace=False)\n",
    "\n",
    "        X_part = X_part[m_part.isin(_rm_classes) == False]\n",
    "        y_part = y_part[m_part.isin(_rm_classes) == False]\n",
    "        m_part = m_part[m_part.isin(_rm_classes) == False]\n",
    "\n",
    "        partitions.append((X_part, y_part, m_part))\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(testset):\n",
    "    \"\"\"Return an evaluation function for server-side (i.e. centralized) evaluation.\"\"\"\n",
    "    x_test, y_test, _ = testset\n",
    "\n",
    "    # The `evaluate` function will be called after every round by the strategy\n",
    "    def evaluate(\n",
    "        server_round: int,\n",
    "        parameters: flwr.common.NDArrays,\n",
    "        config: dict[str, flwr.common.Scalar],\n",
    "    ):\n",
    "        if server_round == NUM_ROUNDS:\n",
    "            # Save final model\n",
    "\n",
    "            np.save(\"fl_weights\", parameters)\n",
    "\n",
    "        model = mk_model()  # Construct the model\n",
    "        model.set_weights(parameters)  # Update model with the latest parameters\n",
    "        loss, _ = model.evaluate(x_test, y_test, verbose=cast(str, 0))\n",
    "\n",
    "        inferences = model.predict(x_test, verbose=cast(str, 0))\n",
    "        y_pred = np.argmax(np.round(inferences), axis=1)\n",
    "        y_true = np.argmax(y_test.to_numpy(), axis=1)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        return (\n",
    "            loss,\n",
    "            {\n",
    "                \"accuracy\": (tn + tp) / (tn + fp + fn + tp),\n",
    "                \"precision\": tp / (tp + fp),\n",
    "                \"recall\": tp / (tp + fn),\n",
    "                \"f1\": 2 * tp / (2 * tp + fp + fn),\n",
    "                \"miss_rate\": fn / (fn + tp),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(flwr.client.NumPyClient):\n",
    "    def __init__(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "        self.model = mk_model()\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.model.set_weights(parameters)\n",
    "        self.model.fit(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            validation_split=0.1,\n",
    "            verbose=cast(str, 0),\n",
    "        )\n",
    "        return self.model.get_weights(), len(self.X_train), {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_client_fn(partitions):\n",
    "    \"\"\"Return a function which creates a new FlowerClient for a given partition.\"\"\"\n",
    "\n",
    "    def client_fn(cid: str) -> FlowerClient:\n",
    "        \"\"\"Create a new FlowerClient for partition i.\"\"\"\n",
    "        x_train, y_train, _ = partitions[int(cid)]\n",
    "\n",
    "        return FlowerClient(x_train, y_train)  # , x_eval_cid, y_eval_cid)\n",
    "\n",
    "    return client_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to what is done in part I, we will add a function to automate the FL process, as we will have multiple experiments to run in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr.common import ndarrays_to_parameters\n",
    "\n",
    "\n",
    "def fl(\n",
    "    partitions,\n",
    "    testset,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    num_rounds=NUM_ROUNDS,\n",
    "    strategy_class=flwr.server.strategy.FedAvg,\n",
    ") -> History:\n",
    "    # Create dataset partitions (needed if your dataset is not pre-partitioned)\n",
    "\n",
    "    # Create FedAvg strategy\n",
    "    strategy = strategy_class(\n",
    "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "        fraction_evaluate=0.0,  # Disable the federated evaluation\n",
    "        min_fit_clients=NUM_CLIENTS,  # Always sample all clients\n",
    "        min_available_clients=NUM_CLIENTS,\n",
    "        evaluate_fn=get_evaluate_fn(testset),  # global evaluation function\n",
    "        initial_parameters=ndarrays_to_parameters(mk_model().get_weights()),\n",
    "    )\n",
    "\n",
    "    # With a dictionary, you tell Flower's VirtualClientEngine that each\n",
    "    # client needs exclusive access to these many resources in order to run\n",
    "    client_resources = {\n",
    "        \"num_cpus\": max(int((os.cpu_count() or 1) / num_clients), 1),\n",
    "        \"num_gpus\": 0.0,\n",
    "    }\n",
    "\n",
    "    # Start simulation\n",
    "    return flwr.simulation.start_simulation(\n",
    "        client_fn=mk_client_fn(partitions),\n",
    "        num_clients=num_clients,\n",
    "        config=flwr.server.ServerConfig(num_rounds=num_rounds),\n",
    "        strategy=strategy,\n",
    "        client_resources=client_resources,\n",
    "        actor_kwargs={\n",
    "            \"on_actor_init_fn\": enable_tf_gpu_growth  # Enable GPU growth upon actor init.\n",
    "        },\n",
    "        ray_init_args={\"num_gpus\": len(tf.config.list_physical_devices(\"GPU\"))},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the different partitions have different sizes since we are using a non-stratified NIID partitioning. Clients are therefore different in terms of both, the number of samples they have and the distribution of classes in their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = load_nslkdd()\n",
    "\n",
    "partitions = partition(NUM_CLIENTS, trainset, 4)\n",
    "for p in partitions:\n",
    "    print(len(p[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finall, we will re-run the training process from Part II to make sure that everything is working as expected, and gather the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_baseline = fl(partitions, testset)\n",
    "fl_weights = np.load(\"fl_weights.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(parameters, testset):\n",
    "    loss, metrics = get_evaluate_fn(testset)(0, parameters, {})\n",
    "    return {\"loss\": loss} | metrics\n",
    "\n",
    "\n",
    "def eval_classes(parameters, testset, classes=None):\n",
    "    X, y, m = testset\n",
    "    if classes is None:\n",
    "        classes = m.unique()\n",
    "    model = mk_model()\n",
    "    model.set_weights(parameters)\n",
    "    inferences = model.predict(X)\n",
    "    y_pred = np.argmax(np.round(inferences), axis=1)\n",
    "    y_true = np.argmax(y.to_numpy(), axis=1)\n",
    "\n",
    "    classes_stats = {}\n",
    "    for cls in classes:\n",
    "        class_filter = m == cls\n",
    "\n",
    "        count = len(m[class_filter])\n",
    "        if not (count > 0):\n",
    "            continue\n",
    "        correct = len(m[(class_filter) & (y_true == y_pred)])\n",
    "        missed = len(m[(class_filter) & (y_true != y_pred)])\n",
    "\n",
    "        classes_stats[cls] = {\n",
    "            \"count\": count,\n",
    "            \"correct\": correct,\n",
    "            \"missed\": missed,\n",
    "            \"rate\": correct / count,\n",
    "        }\n",
    "\n",
    "    ret = pd.DataFrame(classes_stats).T\n",
    "    ret[[\"count\", \"correct\", \"missed\"]].astype(int, copy=False)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(fl_weights, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classes(fl_weights, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: The impact of poisoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a poisoning function. This one is quite versatile so you can try the different types of attacks, such as targeted (also called backdoors attacks) or untargeted ones. This function will be reused for the next examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poison(\n",
    "    shard: tuple[pd.DataFrame, pd.DataFrame, pd.Series], target: list[str]\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Poison the given shard by flipping the labels of the given target.\n",
    "\n",
    "    If target is empty, all samples are poisoned.\n",
    "    If target is \"*\", all malicious samples are poisoned.\n",
    "    Otherwise, only the specified targets are poisoned.\n",
    "\n",
    "    Args:\n",
    "        shard : The dataset shard to poison.\n",
    "        target : A list of classes to target in the given dataset.\n",
    "    \"\"\"\n",
    "    X, y, m = shard\n",
    "    X = X.copy()\n",
    "    y = y.copy()\n",
    "    m = m.copy()\n",
    "\n",
    "    if len(target) == 0:\n",
    "        # if no target is specified, poison all samples (i.e. flip benign/malicious)\n",
    "        y = y.apply(\n",
    "            lambda x: (1, 0) if tuple(x) == (0, 1) else (0, 1),\n",
    "            axis=1,\n",
    "            result_type=\"broadcast\",\n",
    "        )\n",
    "        # else, if \"*\", poison all malicious samples, effectively backdoring all attacks\n",
    "    elif len(target) == 1 and target == [\"*\"]:\n",
    "        y = y.apply(lambda x: (1, 0), axis=1, result_type=\"broadcast\")\n",
    "    else:\n",
    "        # otherwise, poison only the specified targets (i.e. mark samples as benign)\n",
    "        mask = m.isin(target)\n",
    "        idx = y[mask].index  # .to_list()\n",
    "\n",
    "        y.loc[idx] = y.loc[idx].apply(lambda x: (1, 0), axis=1, result_type=\"broadcast\")\n",
    "\n",
    "    return X, y, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Testing poisoning locally\n",
    "\n",
    "Let's validate the impact our poisoning function locally. We will instantiate a participant with a IID shard to see the impact of the poisoning function. We will compare the results of two clients, one with a clean dataset and one with a poisoned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = partition(NUM_CLIENTS, trainset)\n",
    "X, y, m = partitions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FlowerClient(X, y)\n",
    "m = mk_model()\n",
    "w, _, _ = client.fit(m.get_weights(), {})\n",
    "\n",
    "eval_model(w, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classes(w, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = partition(NUM_CLIENTS, trainset)\n",
    "x_poison, y_poison, m_poison = poison(partitions[0], [\"portsweep\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FlowerClient(x_poison, y_poison)\n",
    "m = mk_model()\n",
    "w, _, _ = client.fit(m.get_weights(), {})\n",
    "\n",
    "eval_model(w, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classes(w, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sybil attack on the FL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "NUM_ATTACKERS = 6\n",
    "TARGET = []\n",
    "\n",
    "partitions = partition(NUM_CLIENTS + 1, trainset, 5)\n",
    "benign_partitions = partitions[:NUM_CLIENTS]\n",
    "malicious_part = partitions[-1]\n",
    "\n",
    "# poison the attacker partition\n",
    "x_poison, y_poison, m_poison = poison(malicious_part, TARGET)\n",
    "\n",
    "partitions = benign_partitions + [(x_poison, y_poison, m_poison)] * NUM_ATTACKERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_poisoned = fl(partitions, testset, num_clients=NUM_CLIENTS + NUM_ATTACKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load(\"fl_weights.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(weights, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classes(weights, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Protecting against sybils -- FoolsGold\n",
    "\n",
    "FoolsGold is a modified version of the FedAvg algorithm that is robust to sybil attacks. It is based on the idea that sybils will have a different gradient than honest clients, and that we can detect them by looking at the gradient distribution. \n",
    "\n",
    "FoolsGold works on the assumption that sybils are orchestrated by a single attacker, and therefore have similar gradient updates.\n",
    "\n",
    "![FoolsGold](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server.strategy.aggregate import aggregate\n",
    "from flwr.common import (\n",
    "    Scalar,\n",
    "    Parameters,\n",
    "    FitRes,\n",
    "    parameters_to_ndarrays,\n",
    "    ndarrays_to_parameters,\n",
    ")\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "import sklearn.metrics.pairwise as smp\n",
    "\n",
    "\n",
    "def foolsgold(grads: NDArray) -> NDArray:\n",
    "    \"\"\"FoolsGold algorithm.\n",
    "\n",
    "    The content of this function is based on the original implementation of FoolsGold\n",
    "    devilvered by the authors of the paper. The function is only slightly modified to\n",
    "    provide explicit typing annotations.\n",
    "\n",
    "    Link to FoolsGold's repository:\n",
    "    https://github.com/DistributedML/FoolsGold/blob/master/deep-fg/fg/foolsgold.py\n",
    "\n",
    "    Arguments:\n",
    "        grads (NDArray): A list of historically aggregated gradients, each gradient\n",
    "            being a list of layers as numpy arrays. Unlike in the original\n",
    "            implementation, gradients here are the difference between w_i^r and\n",
    "            w_0^{r-1}, not the gradients themselves.\n",
    "\n",
    "    Returns:\n",
    "        A list of weights, one for each client. The sum of the weights must be 1.\n",
    "    \"\"\"\n",
    "\n",
    "    n_clients = grads.shape[0]\n",
    "    cs: NDArray = smp.cosine_similarity(grads) - np.eye(n_clients)\n",
    "    maxcs: NDArray = np.max(cs, axis=1)\n",
    "    # pardoning\n",
    "    for i in range(n_clients):\n",
    "        for j in range(n_clients):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if maxcs[i] < maxcs[j]:\n",
    "                cs[i][j] = cs[i][j] * maxcs[i] / maxcs[j]\n",
    "    wv: NDArray = 1 - (np.max(cs, axis=1))\n",
    "    wv[wv > 1] = 1\n",
    "    wv[wv < 0] = 0\n",
    "\n",
    "    # Rescale so that max value is wv\n",
    "    wv = wv / np.max(wv)\n",
    "    wv[(wv == 1)] = 0.99\n",
    "\n",
    "    # Logit function\n",
    "    wv = np.log(wv / (1 - wv)) + 0.5\n",
    "    wv[(np.isinf(wv) + wv > 1)] = 1\n",
    "    wv[(wv < 0)] = 0\n",
    "\n",
    "    return wv\n",
    "\n",
    "\n",
    "def flatten_model(model: list[NDArray]) -> NDArray:\n",
    "    \"\"\"Flatten the model into a 1D array.\n",
    "\n",
    "    Arguments:\n",
    "        model: A list of numpy arrays.\n",
    "\n",
    "    Returns:\n",
    "        The flattened model.\n",
    "    \"\"\"\n",
    "    return np.concatenate([layer.ravel() for layer in model])\n",
    "\n",
    "\n",
    "class FoolsGold(FedAvg):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        \"\"\"Initialize simulation strategy.\"\"\"\n",
    "        assert \"initial_parameters\" in kwargs, \"initial_parameters must be provided\"\n",
    "        # Each client has a history of its flattened gradients at each round\n",
    "        self.history: dict[str, NDArray] = {}\n",
    "        self.global_model = parameters_to_ndarrays(kwargs[\"initial_parameters\"])\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[ClientProxy, FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit using FoolsGold algorithm.\n",
    "\n",
    "        FoolsGold\n",
    "\n",
    "        Arguments:\n",
    "            server_round: The current round of the server.\n",
    "            results: A list of tuples containing the client and the result of\n",
    "                the fit operation.\n",
    "            failures: A list of tuples containing the client and the result of\n",
    "                the fit operation or the exception raised during the fit\n",
    "                operation.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the aggregated parameters and the metrics.\n",
    "        \"\"\"\n",
    "\n",
    "        # Call super method to save client states\n",
    "        _, _ = super().aggregate_fit(server_round, results, failures)\n",
    "\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Get results and sort them by client ids\n",
    "        client_results = [\n",
    "            (\n",
    "                proxy.cid,\n",
    "                parameters_to_ndarrays(fit_res.parameters),\n",
    "                fit_res.num_examples,\n",
    "            )\n",
    "            for proxy, fit_res in results\n",
    "        ]\n",
    "        client_results.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Update history\n",
    "        for cid, m, _ in client_results:\n",
    "            grads = flatten_model(m) - flatten_model(self.global_model)\n",
    "            if cid not in self.history:\n",
    "                self.history[cid] = np.zeros_like(grads)\n",
    "            self.history[cid] += grads\n",
    "\n",
    "        # Get a NDArray of shape (num_clients, num_parameters) with flattened models\n",
    "        model_updates = np.array(\n",
    "            [g for _, g in sorted(self.history.items(), key=lambda x: x[0])]\n",
    "        )\n",
    "\n",
    "        weights = foolsgold(model_updates)\n",
    "\n",
    "        weights_results = [(p, w) for (_, p, _), w in zip(client_results, weights)]\n",
    "\n",
    "        agg = aggregate(weights_results)\n",
    "        self.global_model = agg\n",
    "\n",
    "        parameters_aggregated = ndarrays_to_parameters(agg)\n",
    "\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        metrics_aggregated = {}\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "\n",
    "        return parameters_aggregated, metrics_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_fg = fl(partitions, testset, strategy_class=FoolsGold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.load(\"fl_weights.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(weights, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_classes(weights, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metrics = cast(list, history_baseline.metrics_centralized[\"accuracy\"])\n",
    "round = [data[0] for data in baseline_metrics]\n",
    "acc_baseline = [100.0 * data[1] for data in baseline_metrics]\n",
    "\n",
    "plt.plot(round, acc_baseline, label=f\"Baseline: {max(acc_baseline):.4f}\")\n",
    "\n",
    "poisoned_metrics = cast(list, history_poisoned.metrics_centralized[\"accuracy\"])\n",
    "acc_poisoned = [100.0 * data[1] for data in poisoned_metrics]\n",
    "\n",
    "plt.plot(round, acc_poisoned, label=f\"Poisoned: {max(acc_poisoned):.4f}\")\n",
    "\n",
    "fg_metrics = cast(list, history_fg.metrics_centralized[\"accuracy\"])\n",
    "acc_fg = [100.0 * data[1] for data in fg_metrics]\n",
    "\n",
    "plt.plot(round, acc_fg, label=f\"FoolsGold: {max(acc_fg):.4f}\")\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.legend()\n",
    "plt.title(\"Baseline vs. Poisoned vs. Foolsgold \\n 10 clients with 10 clients per round\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
